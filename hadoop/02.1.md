#### Spark配置

* slaves

```bash
#将 slaves.template 拷贝到 slaves
cd /usr/local/spark/
cp ./conf/slaves.template ./conf/slaves

#slaves文件设置Worker节点。编辑slaves内容,把默认内容localhost替换成如下内容：
slave1
slave2
```

* spark-env.sh

```bash
#将 spark-env.sh.template 拷贝到 spark-env.sh
cp ./conf/spark-env.sh.template ./conf/spark-env.sh

#编辑spark-env.sh,添加如下内容：
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
export SPARK_MASTER_HOST=192.168.1.104

#SPARK_MASTER_IP 指定 Spark 集群 master 节点的 IP 地址；
```

配置好后，将master主机上的/usr/local/spark文件夹复制到各个节点上。在master主机上执行如下命令：

```bash
cd /usr/local/
tar -zcf ~/spark.master.tar.gz ./spark
cd ~
scp ./spark.master.tar.gz slave1:/home/hadoop
scp ./spark.master.tar.gz slave2:/home/hadoop
```

#### 启动Spark集群

* 启动master节点

```bash
cd /usr/local/spark/
sbin/start-master.sh

#在master节点上运行jps命令，可以看到多了个Master进程：

15093 Jps
14343 SecondaryNameNode
14121 NameNode
14891 Master
14509 ResourceManager
```

* 启动所有slave节点

```bash
#在master节点主机上运行如下命令：
start-slave.sh spark://master:7077

#分别slave01、slave02节点上运行jps命令，可以看到多了个Worker进程
37553 DataNode
37684 NodeManager
37876 Worker
37924 Jps
```

在浏览器上查看独立集群管理器Spark集群信息

在master主机上打开浏览器，访问http://master:8080

* 测试

```bash
bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 examples/jars/spark-examples_2.11-2.0.2.jar 100 2>&1 | grep "Pi is roughly"
```